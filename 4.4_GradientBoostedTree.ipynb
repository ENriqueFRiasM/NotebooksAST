{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosted Tree is similar to random forest models, but the difference is that trees are built successively. With each iteration, the next tree fits the residual errors from the previous tree in order to improve the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1:  Vacation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-12</th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-18.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t-12  t-11  t-10   t-9   t-8   t-7   t-6   t-5   t-4   t-3   t-2   t-1  \\\n",
       "0  10.0   9.0  -2.0 -17.0 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   \n",
       "1   9.0  -2.0 -17.0 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   3.0   \n",
       "2  -2.0 -17.0 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   3.0  13.0   \n",
       "3 -17.0 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   3.0  13.0  -4.0   \n",
       "4 -18.0  -1.0   3.0   4.0  33.0  -6.0  -3.0 -11.0   3.0  13.0  -4.0 -16.0   \n",
       "\n",
       "      t  \n",
       "0   3.0  \n",
       "1  13.0  \n",
       "2  -4.0  \n",
       "3 -16.0  \n",
       "4 -20.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df1 = pd.read_csv('vacation_lags_12months_features.csv', header=0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "vacat = df1.values\n",
    "# split into lagged variables and original time series\n",
    "X1= vacat[:, 0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
    "y1 = vacat[:,-1]  # slice all rows and last column, essentially separating out 't' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns t-1 to t-12, which are the lagged variables\n",
    "# X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column t, which is the original time series\n",
    "# y1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for Target: 174\n",
      "Training Observations for Target: 130\n",
      "Testing Observations for Target: 44\n"
     ]
    }
   ],
   "source": [
    "# Target Train-Test split\n",
    "from pandas import read_csv\n",
    "\n",
    "Y1 = y1\n",
    "traintarget_size = int(len(Y1) * 0.75)   # Set split\n",
    "train_target, test_target = Y1[0:traintarget_size], Y1[traintarget_size:len(Y1)]\n",
    "\n",
    "print('Observations for Target: %d' % (len(Y1)))\n",
    "print('Training Observations for Target: %d' % (len(train_target)))\n",
    "print('Testing Observations for Target: %d' % (len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for feature: 174\n",
      "Training Observations for feature: 130\n",
      "Testing Observations for feature: 44\n"
     ]
    }
   ],
   "source": [
    "# Features Train-Test split\n",
    "\n",
    "trainfeature_size = int(len(X1) * 0.75)\n",
    "train_feature, test_feature = X1[0:trainfeature_size], X1[trainfeature_size:len(X1)]\n",
    "print('Observations for feature: %d' % (len(X1)))\n",
    "print('Training Observations for feature: %d' % (len(train_feature)))\n",
    "print('Testing Observations for feature: %d' % (len(test_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.977863685438799\n",
      "0.7237380036296147\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosted Regression Model\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# The fraction of samples to be used for fitting the individual base learners. \n",
    "# Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
    "# Create GB model -- hyperparameters \n",
    "gbr = GradientBoostingRegressor(max_features=2,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=500,\n",
    "                                subsample=0.6,\n",
    "                                random_state=99)\n",
    "\n",
    "gbr.fit(train_feature, train_target)\n",
    "\n",
    "print(gbr.score(train_feature, train_target))\n",
    "print(gbr.score(test_feature, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "grid = {'subsample':[0.6],'n_estimators': [100,200,250,300,500], \n",
    "        'learning_rate': [0.01,0.01, 0.1, 0.5],'max_features': [2,3,4,5,6],\n",
    "            'random_state': [17]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7930923716834288 {'subsample': 0.6, 'random_state': 17, 'n_estimators': 300, 'max_features': 6, 'learning_rate': 0.1}\n",
      "0.999581785837155\n"
     ]
    }
   ],
   "source": [
    "# Run grid search\n",
    "# grid = {'n_estimators': [200], 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],'max_features': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'random_state': [17]}\n",
    "\n",
    "test_scores = []\n",
    "train_scores= []\n",
    "\n",
    "#print(list(ParameterGrid(grid)))\n",
    "\n",
    "# Loop through the parameter grid, set the hyperparameters, and save the scores\n",
    "for g in ParameterGrid(grid):\n",
    "    \n",
    "    gbr.set_params(**g)  # ** is \"unpacking\" the dictionary\n",
    "    gbr.fit(train_feature, train_target)\n",
    "    test_scores.append(gbr.score(test_feature, test_target))\n",
    "    train_scores.append(gbr.score(train_feature, train_target))\n",
    "\n",
    "# Find best hyperparameters from the test score and print\n",
    "best_idx = np.argmax(test_scores)\n",
    "\n",
    "#print(train_scores)\n",
    "#print(test_scores)\n",
    "\n",
    "print(test_scores[best_idx], ParameterGrid(grid)[best_idx])  # You don't want negative value\n",
    "print(train_scores[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosted Model Feature Importance\n",
    "# Extract feature importances from the fitted gradient boosting model\n",
    "feature_importances = gbr.feature_importances_\n",
    "\n",
    "# Get the indices of the largest to smallest feature importances\n",
    "sorted_index = np.argsort(feature_importances)[::-1]\n",
    "x1 = range(X1.shape[1])\n",
    "\n",
    "# Create tick labels \n",
    "feature_names = ['t-12', 't-11', 't-10', 't-9', 't-8', 't-7', 't-6', 't-5', 't-4', 't-3',\n",
    "       't-2', 't-1']\n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "plot.bar(x1, feature_importances[sorted_index], tick_label=labels)\n",
    "\n",
    "# Set the tick lables to be the feature names, according to the sorted feature_idx\n",
    "plot.xticks(rotation=90)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Furniture Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-12</th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.069088</td>\n",
       "      <td>-0.002419</td>\n",
       "      <td>0.033839</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.023777</td>\n",
       "      <td>0.042725</td>\n",
       "      <td>0.043720</td>\n",
       "      <td>0.127219</td>\n",
       "      <td>-0.219927</td>\n",
       "      <td>-0.044419</td>\n",
       "      <td>0.121869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.002419</td>\n",
       "      <td>0.033839</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.023777</td>\n",
       "      <td>0.042725</td>\n",
       "      <td>0.043720</td>\n",
       "      <td>0.127219</td>\n",
       "      <td>-0.219927</td>\n",
       "      <td>-0.044419</td>\n",
       "      <td>0.121869</td>\n",
       "      <td>0.003474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.033839</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.023777</td>\n",
       "      <td>0.042725</td>\n",
       "      <td>0.043720</td>\n",
       "      <td>0.127219</td>\n",
       "      <td>-0.219927</td>\n",
       "      <td>-0.044419</td>\n",
       "      <td>0.121869</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.038723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.023777</td>\n",
       "      <td>0.042725</td>\n",
       "      <td>0.043720</td>\n",
       "      <td>0.127219</td>\n",
       "      <td>-0.219927</td>\n",
       "      <td>-0.044419</td>\n",
       "      <td>0.121869</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.038723</td>\n",
       "      <td>0.008674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.023777</td>\n",
       "      <td>0.042725</td>\n",
       "      <td>0.043720</td>\n",
       "      <td>0.127219</td>\n",
       "      <td>-0.219927</td>\n",
       "      <td>-0.044419</td>\n",
       "      <td>0.121869</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.038723</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.024956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t-12      t-11      t-10       t-9       t-8       t-7       t-6  \\\n",
       "0  0.069088 -0.002419  0.033839  0.022829  0.013640  0.011722 -0.023777   \n",
       "1 -0.002419  0.033839  0.022829  0.013640  0.011722 -0.023777  0.042725   \n",
       "2  0.033839  0.022829  0.013640  0.011722 -0.023777  0.042725  0.043720   \n",
       "3  0.022829  0.013640  0.011722 -0.023777  0.042725  0.043720  0.127219   \n",
       "4  0.013640  0.011722 -0.023777  0.042725  0.043720  0.127219 -0.219927   \n",
       "\n",
       "        t-5       t-4       t-3       t-2       t-1         t  \n",
       "0  0.042725  0.043720  0.127219 -0.219927 -0.044419  0.121869  \n",
       "1  0.043720  0.127219 -0.219927 -0.044419  0.121869  0.003474  \n",
       "2  0.127219 -0.219927 -0.044419  0.121869  0.003474  0.038723  \n",
       "3 -0.219927 -0.044419  0.121869  0.003474  0.038723  0.008674  \n",
       "4 -0.044419  0.121869  0.003474  0.038723  0.008674  0.024956  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data, this data has been stationarized\n",
    "df2 = pd.read_csv('~/Desktop/section_4/furniture_lags_12months_features.csv', header=0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "\n",
    "furn = df2.values\n",
    "# split into lagged variables (features) and original time series data (target)\n",
    "X2= furn[:,0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
    "y2 = furn[:,-1]  # slice all rows and last column, essentially separating out 't' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06908776, -0.00241871,  0.03383942, ...,  0.12721928,\n",
       "        -0.21992713, -0.04441943],\n",
       "       [-0.00241871,  0.03383942,  0.02282904, ..., -0.21992713,\n",
       "        -0.04441943,  0.12186938],\n",
       "       [ 0.03383942,  0.02282904,  0.01364014, ..., -0.04441943,\n",
       "         0.12186938,  0.00347408],\n",
       "       ...,\n",
       "       [ 0.08460108, -0.01831672, -0.00127104, ..., -0.01906175,\n",
       "         0.17492792, -0.04829062],\n",
       "       [-0.01831672, -0.00127104,  0.04903607, ...,  0.17492792,\n",
       "        -0.04829062,  0.08136081],\n",
       "       [-0.00127104,  0.04903607, -0.06026621, ..., -0.04829062,\n",
       "         0.08136081, -0.05698937]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns t-1 to t-12, which are the lagged variables\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12186938,  0.00347408,  0.03872338,  0.00867379,  0.02495622,\n",
       "        0.01369304, -0.02164084,  0.03759901,  0.08095082,  0.09170221])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column t, which is the original time series\n",
    "# Give first 10 values of target variable, time series\n",
    "y2[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can alter the splits as 50-50, 60-40, 70-30, 75-25, 80-20, and 85-15, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for Target: 317\n",
      "Training Observations for Target: 237\n",
      "Testing Observations for Target: 80\n"
     ]
    }
   ],
   "source": [
    "# Target Train-Test split\n",
    "from pandas import read_csv\n",
    "\n",
    "Y2 = y2\n",
    "traintarget_size = int(len(Y2) * 0.75)   # Set split\n",
    "train_target, test_target = Y2[0:traintarget_size], Y2[traintarget_size:len(Y2)]\n",
    "\n",
    "print('Observations for Target: %d' % (len(Y2)))\n",
    "print('Training Observations for Target: %d' % (len(train_target)))\n",
    "print('Testing Observations for Target: %d' % (len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for feature: 317\n",
      "Training Observations for feature: 237\n",
      "Testing Observations for feature: 80\n"
     ]
    }
   ],
   "source": [
    "# Features Train-Test split\n",
    "\n",
    "trainfeature_size = int(len(X2) * 0.75)\n",
    "train_feature, test_feature = X2[0:trainfeature_size], X2[trainfeature_size:len(X2)]\n",
    "print('Observations for feature: %d' % (len(X2)))\n",
    "print('Training Observations for feature: %d' % (len(train_feature)))\n",
    "print('Testing Observations for feature: %d' % (len(test_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9646015239785328\n",
      "0.9023134137739652\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# The fraction of samples to be used for fitting the individual base learners. \n",
    "# Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
    "# Create GB model -- hyperparameters \n",
    "gbr = GradientBoostingRegressor(max_features=7,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=500,\n",
    "                                subsample=0.6,\n",
    "                                random_state=99)\n",
    "\n",
    "gbr.fit(train_feature, train_target)\n",
    "\n",
    "print(gbr.score(train_feature, train_target))\n",
    "print(gbr.score(test_feature, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GB model is  better than Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract feature importances from gradient boosting models to understand which features are the best predictors. Sometimes it's nice to try different tree-based models and look at the feature importances from all of them. This can help average out any peculiarities that may arise from one particular model.\n",
    "\n",
    "The feature importances are stored as a numpy array in the .feature_importances_ property of the gradient boosting model. We'll need to get the sorted indices of the feature importances, using np.argsort(), in order to make a nice plot. We want the features from largest to smallest, so we will use Python's indexing to reverse the sorted importances like feat_importances[::-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosted Model Feature Importance\n",
    "# Extract feature importances from the fitted gradient boosting model\n",
    "feature_importances = gbr.feature_importances_\n",
    "\n",
    "# Get the indices of the largest to smallest feature importances\n",
    "sorted_index = np.argsort(feature_importances)[::-1]\n",
    "x2 = range(X2.shape[1])\n",
    "\n",
    "# Create tick labels \n",
    "feature_names = ['t-12', 't-11', 't-10', 't-9', 't-8', 't-7', 't-6', 't-5', 't-4', 't-3',\n",
    "       't-2', 't-1']\n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "plot.bar(x2, feature_importances[sorted_index], tick_label=labels)\n",
    "\n",
    "# Set the tick lables to be the feature names, according to the sorted feature_idx\n",
    "plot.xticks(rotation=90)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the feature importances are not exactly the same as the random forest model's but they are close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Bank of America Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-12</th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.687537</td>\n",
       "      <td>1.469485</td>\n",
       "      <td>1.441042</td>\n",
       "      <td>1.525887</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.469485</td>\n",
       "      <td>1.441042</td>\n",
       "      <td>1.525887</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "      <td>1.595426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.441042</td>\n",
       "      <td>1.525887</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "      <td>1.595426</td>\n",
       "      <td>1.699101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.525887</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "      <td>1.595426</td>\n",
       "      <td>1.699101</td>\n",
       "      <td>1.941008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.476664</td>\n",
       "      <td>1.412676</td>\n",
       "      <td>1.341841</td>\n",
       "      <td>0.879137</td>\n",
       "      <td>0.709480</td>\n",
       "      <td>0.987102</td>\n",
       "      <td>1.002662</td>\n",
       "      <td>1.232781</td>\n",
       "      <td>1.282093</td>\n",
       "      <td>1.595426</td>\n",
       "      <td>1.699101</td>\n",
       "      <td>1.941008</td>\n",
       "      <td>1.707245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t-12      t-11      t-10       t-9       t-8       t-7       t-6  \\\n",
       "0  1.687537  1.469485  1.441042  1.525887  1.476664  1.412676  1.341841   \n",
       "1  1.469485  1.441042  1.525887  1.476664  1.412676  1.341841  0.879137   \n",
       "2  1.441042  1.525887  1.476664  1.412676  1.341841  0.879137  0.709480   \n",
       "3  1.525887  1.476664  1.412676  1.341841  0.879137  0.709480  0.987102   \n",
       "4  1.476664  1.412676  1.341841  0.879137  0.709480  0.987102  1.002662   \n",
       "\n",
       "        t-5       t-4       t-3       t-2       t-1         t  \n",
       "0  0.879137  0.709480  0.987102  1.002662  1.232781  1.282093  \n",
       "1  0.709480  0.987102  1.002662  1.232781  1.282093  1.595426  \n",
       "2  0.987102  1.002662  1.232781  1.282093  1.595426  1.699101  \n",
       "3  1.002662  1.232781  1.282093  1.595426  1.699101  1.941008  \n",
       "4  1.232781  1.282093  1.595426  1.699101  1.941008  1.707245  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data, this data has been stationarized\n",
    "df3 = pd.read_csv('~/Desktop/section_4/bac_lags_12months_features.csv', header=0)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "\n",
    "bac = df3.values\n",
    "# split into lagged variables (features) and original time series data (target)\n",
    "X3= bac[:,0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
    "y3 = bac[:,-1]  # slice all rows and last column, essentially separating out 't' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.68753707,  1.46948457,  1.44104242, ...,  0.98710191,\n",
       "         1.00266206,  1.23278129],\n",
       "       [ 1.46948457,  1.44104242,  1.52588725, ...,  1.00266206,\n",
       "         1.23278129,  1.28209293],\n",
       "       [ 1.44104242,  1.52588725,  1.47666395, ...,  1.23278129,\n",
       "         1.28209293,  1.59542644],\n",
       "       ...,\n",
       "       [30.09263229, 28.80098343, 26.88482857, ..., 26.28380585,\n",
       "        28.81011391, 30.47911263],\n",
       "       [28.80098343, 26.88482857, 27.76469421, ..., 28.81011391,\n",
       "        30.47911263, 27.32987022],\n",
       "       [26.88482857, 27.76469421, 24.22343063, ..., 30.47911263,\n",
       "        27.32987022, 29.17000008]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns t-1 to t-12, which are the lagged variables\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.28209293, 1.59542644, 1.69910097, 1.94100773, 1.70724475,\n",
       "       1.65948939, 1.91634405, 1.76750135, 1.85432637, 1.70548344])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column t, which is the original time series\n",
    "# Give first 10 values of target variable, time series\n",
    "y3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for Target: 345\n",
      "Training Observations for Target: 258\n",
      "Testing Observations for Target: 87\n"
     ]
    }
   ],
   "source": [
    "# Target Train-Test split\n",
    "from pandas import read_csv\n",
    "\n",
    "Y3 = y3\n",
    "traintarget_size = int(len(Y3) * 0.75)   # Set split\n",
    "train_target, test_target = Y3[0:traintarget_size], Y3[traintarget_size:len(Y3)]\n",
    "\n",
    "print('Observations for Target: %d' % (len(Y3)))\n",
    "print('Training Observations for Target: %d' % (len(train_target)))\n",
    "print('Testing Observations for Target: %d' % (len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for feature: 345\n",
      "Training Observations for feature: 258\n",
      "Testing Observations for feature: 87\n"
     ]
    }
   ],
   "source": [
    "# Features Train-Test split\n",
    "\n",
    "trainfeature_size = int(len(X3) * 0.75)\n",
    "train_feature, test_feature = X3[0:trainfeature_size], X3[trainfeature_size:len(X3)]\n",
    "print('Observations for feature: %d' % (len(X3)))\n",
    "print('Training Observations for feature: %d' % (len(train_feature)))\n",
    "print('Testing Observations for feature: %d' % (len(test_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99460446666043\n",
      "0.9521949350955565\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# The fraction of samples to be used for fitting the individual base learners. \n",
    "# Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
    "# Create GB model -- hyperparameters\n",
    "gbr = GradientBoostingRegressor(max_features=8,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=500,\n",
    "                                subsample=0.6,\n",
    "                                random_state=99)\n",
    "\n",
    "gbr.fit(train_feature, train_target)\n",
    "\n",
    "print(gbr.score(train_feature, train_target))\n",
    "print(gbr.score(test_feature, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosted Model Feature Importance\n",
    "# Extract feature importances from the fitted gradient boosting model\n",
    "feature_importances = gbr.feature_importances_\n",
    "\n",
    "# Get the indices of the largest to smallest feature importances\n",
    "sorted_index = np.argsort(feature_importances)[::-1]\n",
    "x3 = range(X3.shape[1])\n",
    "\n",
    "# Create tick labels \n",
    "feature_names = ['t-12', 't-11', 't-10', 't-9', 't-8', 't-7', 't-6', 't-5', 't-4', 't-3',\n",
    "       't-2', 't-1']\n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "plot.bar(x3, feature_importances[sorted_index], tick_label=labels)\n",
    "\n",
    "# Set the tick lables to be the feature names, according to the sorted feature_idx\n",
    "plot.xticks(rotation=90)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4:  J.P. Morgan Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-12</th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.083579</td>\n",
       "      <td>2.884144</td>\n",
       "      <td>2.884144</td>\n",
       "      <td>3.377686</td>\n",
       "      <td>3.223591</td>\n",
       "      <td>2.907553</td>\n",
       "      <td>2.733733</td>\n",
       "      <td>2.019471</td>\n",
       "      <td>1.319170</td>\n",
       "      <td>1.482032</td>\n",
       "      <td>1.427535</td>\n",
       "      <td>1.742920</td>\n",
       "      <td>2.191100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.884144</td>\n",
       "      <td>2.884144</td>\n",
       "      <td>3.377686</td>\n",
       "      <td>3.223591</td>\n",
       "      <td>2.907553</td>\n",
       "      <td>2.733733</td>\n",
       "      <td>2.019471</td>\n",
       "      <td>1.319170</td>\n",
       "      <td>1.482032</td>\n",
       "      <td>1.427535</td>\n",
       "      <td>1.742920</td>\n",
       "      <td>2.191100</td>\n",
       "      <td>2.340254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.884144</td>\n",
       "      <td>3.377686</td>\n",
       "      <td>3.223591</td>\n",
       "      <td>2.907553</td>\n",
       "      <td>2.733733</td>\n",
       "      <td>2.019471</td>\n",
       "      <td>1.319170</td>\n",
       "      <td>1.482032</td>\n",
       "      <td>1.427535</td>\n",
       "      <td>1.742920</td>\n",
       "      <td>2.191100</td>\n",
       "      <td>2.340254</td>\n",
       "      <td>2.761165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.377686</td>\n",
       "      <td>3.223591</td>\n",
       "      <td>2.907553</td>\n",
       "      <td>2.733733</td>\n",
       "      <td>2.019471</td>\n",
       "      <td>1.319170</td>\n",
       "      <td>1.482032</td>\n",
       "      <td>1.427535</td>\n",
       "      <td>1.742920</td>\n",
       "      <td>2.191100</td>\n",
       "      <td>2.340254</td>\n",
       "      <td>2.761165</td>\n",
       "      <td>2.879019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.223591</td>\n",
       "      <td>2.907553</td>\n",
       "      <td>2.733733</td>\n",
       "      <td>2.019471</td>\n",
       "      <td>1.319170</td>\n",
       "      <td>1.482032</td>\n",
       "      <td>1.427535</td>\n",
       "      <td>1.742920</td>\n",
       "      <td>2.191100</td>\n",
       "      <td>2.340254</td>\n",
       "      <td>2.761165</td>\n",
       "      <td>2.879019</td>\n",
       "      <td>2.909008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t-12      t-11      t-10       t-9       t-8       t-7       t-6  \\\n",
       "0  3.083579  2.884144  2.884144  3.377686  3.223591  2.907553  2.733733   \n",
       "1  2.884144  2.884144  3.377686  3.223591  2.907553  2.733733  2.019471   \n",
       "2  2.884144  3.377686  3.223591  2.907553  2.733733  2.019471  1.319170   \n",
       "3  3.377686  3.223591  2.907553  2.733733  2.019471  1.319170  1.482032   \n",
       "4  3.223591  2.907553  2.733733  2.019471  1.319170  1.482032  1.427535   \n",
       "\n",
       "        t-5       t-4       t-3       t-2       t-1         t  \n",
       "0  2.019471  1.319170  1.482032  1.427535  1.742920  2.191100  \n",
       "1  1.319170  1.482032  1.427535  1.742920  2.191100  2.340254  \n",
       "2  1.482032  1.427535  1.742920  2.191100  2.340254  2.761165  \n",
       "3  1.427535  1.742920  2.191100  2.340254  2.761165  2.879019  \n",
       "4  1.742920  2.191100  2.340254  2.761165  2.879019  2.909008  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df4 = pd.read_csv('~/Desktop/section_4/jpm_lags_12months_features.csv', header=0)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "\n",
    "jpm = df4.values\n",
    "# split into lagged variables and original time series\n",
    "X4= jpm[:, 0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
    "y4 = jpm[:,-1]  # slice all rows and last column, essentially separating out 't' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.0835793 ,   2.88414359,   2.88414359, ...,   1.4820317 ,\n",
       "          1.42753482,   1.74292016],\n",
       "       [  2.88414359,   2.88414359,   3.37768602, ...,   1.42753482,\n",
       "          1.74292016,   2.19109988],\n",
       "       [  2.88414359,   3.37768602,   3.22359133, ...,   1.74292016,\n",
       "          2.19109988,   2.34025359],\n",
       "       ...,\n",
       "       [110.3382339 , 108.6626434 , 105.7192307 , ..., 104.3789597 ,\n",
       "        110.1318283 , 115.0781479 ],\n",
       "       [108.6626434 , 105.7192307 , 107.8235474 , ..., 110.1318283 ,\n",
       "        115.0781479 , 108.9869385 ],\n",
       "       [105.7192307 , 107.8235474 ,  94.66440582, ..., 115.0781479 ,\n",
       "        108.9869385 , 116.754715  ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns t-1 to t-12, which are the lagged variables\n",
    "X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.19109988, 2.34025359, 2.7611649 , 2.87901878, 2.90900755,\n",
       "       3.48740601, 3.6064899 , 3.48626947, 3.40040255, 2.90236306])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column t, which is the original time series\n",
    "y4[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for Target: 345\n",
      "Training Observations for Target: 241\n",
      "Testing Observations for Target: 104\n"
     ]
    }
   ],
   "source": [
    "# Target Train-Test split\n",
    "from pandas import read_csv\n",
    "\n",
    "Y4 = y4\n",
    "traintarget_size = int(len(Y4) * 0.70)   # Set split\n",
    "train_target, test_target = Y4[0:traintarget_size], Y4[traintarget_size:len(Y4)]\n",
    "\n",
    "print('Observations for Target: %d' % (len(Y4)))\n",
    "print('Training Observations for Target: %d' % (len(train_target)))\n",
    "print('Testing Observations for Target: %d' % (len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for feature: 345\n",
      "Training Observations for feature: 241\n",
      "Testing Observations for feature: 104\n"
     ]
    }
   ],
   "source": [
    "# Features Train-Test split\n",
    "\n",
    "trainfeature_size = int(len(X4) * 0.70)\n",
    "train_feature, test_feature = X4[0:trainfeature_size], X4[trainfeature_size:len(X4)]\n",
    "print('Observations for feature: %d' % (len(X4)))\n",
    "print('Training Observations for feature: %d' % (len(train_feature)))\n",
    "print('Testing Observations for feature: %d' % (len(test_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9839877776490134\n",
      "-1.1714873104202743\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# The fraction of samples to be used for fitting the individual base learners. \n",
    "# Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
    "# Create GB model -- hyperparameters \n",
    "gbr = GradientBoostingRegressor(max_features=3,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=500,\n",
    "                                subsample=0.6,\n",
    "                                random_state=99)\n",
    "\n",
    "gbr.fit(train_feature, train_target)\n",
    "\n",
    "print(gbr.score(train_feature, train_target))\n",
    "print(gbr.score(test_feature, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosted Model Feature Importance\n",
    "# Extract feature importances from the fitted gradient boosting model\n",
    "feature_importances = gbr.feature_importances_\n",
    "\n",
    "# Get the indices of the largest to smallest feature importances\n",
    "sorted_index = np.argsort(feature_importances)[::-1]\n",
    "x4 = range(X4.shape[1])\n",
    "\n",
    "# Create tick labels \n",
    "feature_names = ['t-12', 't-11', 't-10', 't-9', 't-8', 't-7', 't-6', 't-5', 't-4', 't-3',\n",
    "       't-2', 't-1']\n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "plot.bar(x4, feature_importances[sorted_index], tick_label=labels)\n",
    "\n",
    "# Set the tick lables to be the feature names, according to the sorted feature_idx\n",
    "plot.xticks(rotation=90)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Average Temperature Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-12</th>\n",
       "      <th>t-11</th>\n",
       "      <th>t-10</th>\n",
       "      <th>t-9</th>\n",
       "      <th>t-8</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.250412</td>\n",
       "      <td>17.050412</td>\n",
       "      <td>23.950412</td>\n",
       "      <td>24.850412</td>\n",
       "      <td>15.650412</td>\n",
       "      <td>6.550412</td>\n",
       "      <td>-10.549588</td>\n",
       "      <td>-21.549588</td>\n",
       "      <td>-18.749588</td>\n",
       "      <td>-23.749588</td>\n",
       "      <td>-9.749588</td>\n",
       "      <td>-4.349588</td>\n",
       "      <td>11.750412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17.050412</td>\n",
       "      <td>23.950412</td>\n",
       "      <td>24.850412</td>\n",
       "      <td>15.650412</td>\n",
       "      <td>6.550412</td>\n",
       "      <td>-10.549588</td>\n",
       "      <td>-21.549588</td>\n",
       "      <td>-18.749588</td>\n",
       "      <td>-23.749588</td>\n",
       "      <td>-9.749588</td>\n",
       "      <td>-4.349588</td>\n",
       "      <td>11.750412</td>\n",
       "      <td>19.150412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>23.950412</td>\n",
       "      <td>24.850412</td>\n",
       "      <td>15.650412</td>\n",
       "      <td>6.550412</td>\n",
       "      <td>-10.549588</td>\n",
       "      <td>-21.549588</td>\n",
       "      <td>-18.749588</td>\n",
       "      <td>-23.749588</td>\n",
       "      <td>-9.749588</td>\n",
       "      <td>-4.349588</td>\n",
       "      <td>11.750412</td>\n",
       "      <td>19.150412</td>\n",
       "      <td>23.250412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24.850412</td>\n",
       "      <td>15.650412</td>\n",
       "      <td>6.550412</td>\n",
       "      <td>-10.549588</td>\n",
       "      <td>-21.549588</td>\n",
       "      <td>-18.749588</td>\n",
       "      <td>-23.749588</td>\n",
       "      <td>-9.749588</td>\n",
       "      <td>-4.349588</td>\n",
       "      <td>11.750412</td>\n",
       "      <td>19.150412</td>\n",
       "      <td>23.250412</td>\n",
       "      <td>19.250412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15.650412</td>\n",
       "      <td>6.550412</td>\n",
       "      <td>-10.549588</td>\n",
       "      <td>-21.549588</td>\n",
       "      <td>-18.749588</td>\n",
       "      <td>-23.749588</td>\n",
       "      <td>-9.749588</td>\n",
       "      <td>-4.349588</td>\n",
       "      <td>11.750412</td>\n",
       "      <td>19.150412</td>\n",
       "      <td>23.250412</td>\n",
       "      <td>19.250412</td>\n",
       "      <td>18.750412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        t-12       t-11       t-10        t-9        t-8        t-7  \\\n",
       "0   8.250412  17.050412  23.950412  24.850412  15.650412   6.550412   \n",
       "1  17.050412  23.950412  24.850412  15.650412   6.550412 -10.549588   \n",
       "2  23.950412  24.850412  15.650412   6.550412 -10.549588 -21.549588   \n",
       "3  24.850412  15.650412   6.550412 -10.549588 -21.549588 -18.749588   \n",
       "4  15.650412   6.550412 -10.549588 -21.549588 -18.749588 -23.749588   \n",
       "\n",
       "         t-6        t-5        t-4        t-3        t-2        t-1          t  \n",
       "0 -10.549588 -21.549588 -18.749588 -23.749588  -9.749588  -4.349588  11.750412  \n",
       "1 -21.549588 -18.749588 -23.749588  -9.749588  -4.349588  11.750412  19.150412  \n",
       "2 -18.749588 -23.749588  -9.749588  -4.349588  11.750412  19.150412  23.250412  \n",
       "3 -23.749588  -9.749588  -4.349588  11.750412  19.150412  23.250412  19.250412  \n",
       "4  -9.749588  -4.349588  11.750412  19.150412  23.250412  19.250412  18.750412  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df5 = pd.read_csv('~/Desktop/section_4/temp_lags_12months_features.csv', header=0)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df5.values\n",
    "# split into lagged variables and original time series\n",
    "X5= temp[:,0:-1]  # slice all rows and start with column 0 and go up to but not including the last column\n",
    "y5 = temp[:,-1]  # slice all rows and last column, essentially separating out 't' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.25041237,  17.05041237,  23.95041237, ..., -23.74958763,\n",
       "         -9.74958763,  -4.34958763],\n",
       "       [ 17.05041237,  23.95041237,  24.85041237, ...,  -9.74958763,\n",
       "         -4.34958763,  11.75041237],\n",
       "       [ 23.95041237,  24.85041237,  15.65041237, ...,  -4.34958763,\n",
       "         11.75041237,  19.15041237],\n",
       "       ...,\n",
       "       [ -8.34958763, -21.54958763, -26.64958763, ...,  23.25041237,\n",
       "         18.35041237,   3.15041237],\n",
       "       [-21.54958763, -26.64958763, -18.44958763, ...,  18.35041237,\n",
       "          3.15041237, -17.54958763],\n",
       "       [-26.64958763, -18.44958763, -13.34958763, ...,   3.15041237,\n",
       "        -17.54958763, -17.44958763]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns t-1 to t-12, which are the lagged variables\n",
    "X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.75041237,  19.15041237,  23.25041237,  19.25041237,\n",
       "        18.75041237,   3.75041237, -13.34958763, -20.74958763,\n",
       "       -42.64958763, -24.44958763])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column t, which is the original time series\n",
    "y5[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for Target: 957\n",
      "Training Observations for Target: 765\n",
      "Testing Observations for Target: 192\n"
     ]
    }
   ],
   "source": [
    "# Target Train-Test split\n",
    "from pandas import read_csv\n",
    "\n",
    "Y5 = y5\n",
    "traintarget_size = int(len(Y5) * 0.80)   # Set split\n",
    "train_target, test_target = Y5[0:traintarget_size], Y5[traintarget_size:len(Y5)]\n",
    "\n",
    "print('Observations for Target: %d' % (len(Y5)))\n",
    "print('Training Observations for Target: %d' % (len(train_target)))\n",
    "print('Testing Observations for Target: %d' % (len(test_target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations for feature: 957\n",
      "Training Observations for feature: 765\n",
      "Testing Observations for feature: 192\n"
     ]
    }
   ],
   "source": [
    "# Features Train-Test split\n",
    "\n",
    "trainfeature_size = int(len(X5) * 0.80)\n",
    "train_feature, test_feature = X5[0:trainfeature_size], X5[trainfeature_size:len(X5)]\n",
    "print('Observations for feature: %d' % (len(X5)))\n",
    "print('Training Observations for feature: %d' % (len(train_feature)))\n",
    "print('Testing Observations for feature: %d' % (len(test_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966727972479287\n",
      "0.9382694989776716\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# The fraction of samples to be used for fitting the individual base learners. \n",
    "# Choosing subsample < 1.0 leads to a reduction of variance and an increase in bias.\n",
    "# Create GB model -- hyperparameters \n",
    "gbr = GradientBoostingRegressor(max_features=8,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=500,\n",
    "                                subsample=0.6,\n",
    "                                random_state=99)\n",
    "\n",
    "gbr.fit(train_feature, train_target)\n",
    "\n",
    "print(gbr.score(train_feature, train_target))\n",
    "print(gbr.score(test_feature, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEDCAYAAAAlRP8qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQt0lEQVR4nO3df5BdZ13H8feHtJEZKNBpdgZsUlLbgkRECkvEP1CEIq3VVKCFdAYpCgbQgLaMQ4BOB4uOUBkYlSBEZUSBSUtVXGggCuWHyADZltqalmgopVmL4wLlVxFK7Nc/7i3e2dzN3k3P3R9P36+ZOznnOc+c73PPnv3suc899yZVhSRp9XvAcg9AktQNA12SGmGgS1IjDHRJaoSBLkmNMNAlqRHHLVfhdevW1caNG5ervCStStddd91Xq2pi2LZlC/SNGzcyPT29XOUlaVVK8uX5tjnlIkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWrEsn2w6L7YuOOazvd52xvO7XyfkrSUvEKXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqxEiBnuTsJAeSHEyyY8j2FyaZTXJD//Hi7ocqSTqaBb8+N8kaYCfwDGAG2JdkqqpuntP1yqraPoYxSpJGMMoV+mbgYFXdWlV3A7uB88Y7LEnSYo0S6CcDhwbWZ/ptcz0nyY1Jrk6yoZPRSZJGNkqgZ0hbzVn/ALCxqh4HfAR419AdJduSTCeZnp2dXdxIJUlHNUqgzwCDV9zrgTsGO1TV16rq+/3VPweeOGxHVbWrqiaranJiYuJYxitJmscogb4POCPJqUnWAluBqcEOSR4xsLoFuKW7IUqSRrHgXS5VdTjJdmAvsAZ4Z1XtT3I5MF1VU8ArkmwBDgNfB144xjFLkoZYMNABqmoPsGdO22UDy68GXt3t0CRJi+EnRSWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGjFSoCc5O8mBJAeT7DhKv/OTVJLJ7oYoSRrFgoGeZA2wEzgH2ARcmGTTkH4nAK8APtv1ICVJCxvlCn0zcLCqbq2qu4HdwHlD+r0euAL4XofjkySNaJRAPxk4NLA+02/7oSRnAhuq6oMdjk2StAijBHqGtNUPNyYPAN4CvHLBHSXbkkwnmZ6dnR19lJKkBY0S6DPAhoH19cAdA+snAI8FPp7kNuDJwNSwN0araldVTVbV5MTExLGPWpJ0hFECfR9wRpJTk6wFtgJT926sqm9W1bqq2lhVG4HPAFuqanosI5YkDbVgoFfVYWA7sBe4BbiqqvYnuTzJlnEPUJI0muNG6VRVe4A9c9oum6fvU+/7sCRJi+UnRSWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktSI45Z7ACvZxh3XdL7P295wbuf7lCQY8Qo9ydlJDiQ5mGTHkO0vTXJTkhuSfCrJpu6HKkk6mgUDPckaYCdwDrAJuHBIYL+3qn6yqh4PXAG8ufORSpKOapQr9M3Awaq6taruBnYD5w12qKpvDaw+CKjuhihJGsUoc+gnA4cG1meAn57bKclvAZcAa4GndTI6SdLIRrlCz5C2I67Aq2pnVZ0GvAq4dOiOkm1JppNMz87OLm6kkqSjGiXQZ4ANA+vrgTuO0n838CvDNlTVrqqarKrJiYmJ0UcpSVrQKIG+DzgjyalJ1gJbganBDknOGFg9F/iP7oYoSRrFgnPoVXU4yXZgL7AGeGdV7U9yOTBdVVPA9iRnAT8A7gQuGuegJUlHGumDRVW1B9gzp+2ygeXf7nhckqRF8qP/ktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNGCnQk5yd5ECSg0l2DNl+SZKbk9yY5KNJHtn9UCVJR7NgoCdZA+wEzgE2ARcm2TSn2+eByap6HHA1cEXXA5UkHd0oV+ibgYNVdWtV3Q3sBs4b7FBVH6uq7/ZXPwOs73aYkqSFjBLoJwOHBtZn+m3zeRHwofsyKEnS4h03Qp8MaauhHZPnA5PAz82zfRuwDeCUU04ZcYiSpFGMcoU+A2wYWF8P3DG3U5KzgNcCW6rq+8N2VFW7qmqyqiYnJiaOZbySpHmMEuj7gDOSnJpkLbAVmBrskORM4B30wvy/ux+mJGkhCwZ6VR0GtgN7gVuAq6pqf5LLk2zpd/sj4MHA+5LckGRqnt1JksZklDl0qmoPsGdO22UDy2d1PC5J0iL5SVFJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEaMFOhJzk5yIMnBJDuGbP/ZJNcnOZzk/O6HKUlayIKBnmQNsBM4B9gEXJhk05xutwMvBN7b9QAlSaM5boQ+m4GDVXUrQJLdwHnAzfd2qKrb+tvuGcMYJUkjGGXK5WTg0MD6TL9NkrSCjBLoGdJWx1IsybYk00mmZ2dnj2UXkqR5jBLoM8CGgfX1wB3HUqyqdlXVZFVNTkxMHMsuJEnzGCXQ9wFnJDk1yVpgKzA13mFJkhZrwUCvqsPAdmAvcAtwVVXtT3J5ki0ASZ6UZAa4AHhHkv3jHLQk6Uij3OVCVe0B9sxpu2xgeR+9qRhJ0jLxk6KS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiJH+xyKN18Yd13S+z9vecG7n+5S0snmFLkmNMNAlqREGuiQ1wjn0+5Gu5+qdp5dWFq/QJakRBrokNcIpF3XKWzCl5eMVuiQ1wkCXpEYY6JLUCOfQtSo5Vy8daaQr9CRnJzmQ5GCSHUO2/0iSK/vbP5tkY9cDlSQd3YJX6EnWADuBZwAzwL4kU1V180C3FwF3VtXpSbYCbwSeN44BS0tpqV4JLNWHvvxwWdtGmXLZDBysqlsBkuwGzgMGA/084HX95auBtyZJVVWHY5W0CqzWP4LLXacLo0y5nAwcGlif6bcN7VNVh4FvAid1MUBJ0miy0EV0kguAZ1bVi/vrvwpsrqqXD/TZ3+8z01//Yr/P1+bsaxuwrb/6aOBAV0/kKNYBX22ghnVWdp2Wnot1Vm4NgEdW1cSwDaNMucwAGwbW1wN3zNNnJslxwEOBr8/dUVXtAnaNMuKuJJmuqsnVXsM6K7tOS8/FOiu3xkJGmXLZB5yR5NQka4GtwNScPlPARf3l84FrnT+XpKW14BV6VR1Osh3YC6wB3llV+5NcDkxX1RTwl8DfJDlI78p86zgHLUk60kgfLKqqPcCeOW2XDSx/D7ig26F1ZimmeJZqGsk6K7dOS8/FOiu3xlEt+KaoJGl18LtcJKkRBrokNcJAl1aJJE9Y7jGsRknWLfcYlkpTgZ7kIUlOG9L+uDHXfGKSE8dVQ/ddkmeMab8nJjlhDPt9wpzHE4GpJGd2HexJHprkeUkuSXJxf/lhXdZYKknOSfKlJJ/qH6v9wGeTzCR5eod1fjzJh5Jck+S0JH+V5BtJPpfkMV3VWbSqauIBPJfeB55uAPYDTxrYdn2Hdd4NrOsvP5PeVx58BPgycMESPM+bOtzXrw8srwc+CnwD+DTwqA7rfB34C+Dp9N+IX4bz4/YO9/WjwF/T+4qL/wVu7z9eBxzfUY17+j+Hjw08/qf/77UdPpcXAF8E/gy4tP94e7/tBR3W2QDsBv4ZeM3gcQLe32GdG4DHAD8DfA14cr/9MR3nwCeBXwYu7P/ubwXSb/toV3UWPa7lKtz5E+n9IB/RX94MfAF4dn/98x3WuWlg+dPAxv7yOuBfO6rx7HkezwFmO3wu1w8sXwW8hN6rtmd1eVLS+4qH7cC/AP8J/PG9v2gdnwNT8zw+ANzVYZ1rgacO/KzeAjwI+H1gV0c1zgc+AfziQNuXxnDMDgAPG9J+IvDvHdb5J+ClwOOBP+3/7pzU39bl7+fgOX1ozrYbOqzz+YHlg/ONYakfLf0HF2uq6isAVfW5JD8PfDDJeqDLezMfkOQhVfUteldRt/drfrX/tQdduBJ4D8PH/cCOasz1qKp6bn/575NcdtTei3NXVb2V3rdwnkLvauZt/Zf1u6vqNR3VeQrwfOA7c9pD7498V06qqo8DVNXfJXltVd0FXJrkC10UqKqrk3wYeH2SXwNeSbfn8b0yz37v6W/rykRVvb2//PIkzwc+mWTLPPWP1TeSvAR4CHBnkovpXaycxZHnxX2xZmD5zXO2re2wzqK0FOjfTnJaVX0RoKq+kuSpwPuBn+iwzu8BH0uyk94V5/uS/APwNODDHdW4EXhTVf3b3A1JzuqoBsD6JH9C7xd3IsnxVfWD/rbjO6zzw2CoqtuBK4Arkjyabj9V/Bngu1X1iSMGkHT5RXCz/UC6lt6rptv6NUKH70tV1XeAi5M8HngX0PlcPfAHwPVJ/pH//1bVU+j9/wev77DO8UkeWL0PIVJV707yX/Q+gf6gDutcRG/a6B7gF+hNieylNy3yGx3W2ZnkwVX1nap6272NSU6nNwW7LJr5YFGSn6J3JXhwTvvxwHOr6j0d1jqd3snxKHp/FGfozQPu7Wj/TwG+3A+/udsmq2q6ozoXzWmaqqo7kzwceEVXV85J3lxVl3Sxr5Wg/yrjTcAmelN9v9u/gDiJ3lTM346hZoAT+q8Mu973ifTeDzqZ3h/fGWBvVd3ZYY2L6U1FfGJO+5nAFVU1ljet72+aCXSpdUmurypvXVykpTpuK+Hn09Rti/NJctOY93/9OPe/VDVarDNQb9WfA3Q7p71wsTaOGSzdcVvSn88wzcyhJ3n2fJuAh4+7/Jj3v1Q1VnWdFs+BJG+sqlf1V68Z0nZf99/cMYPxH7elrjOqlq7QrwS20LsPdPDxS4zhzpAkbxxYvWZI26qo0Vid5s4Bem9OAlBVl/YXz+lw/y0eMxj/cVvqOqNZrvslu34A1wGPnWfboTHUO+JeU+DG1VajpTotnQPAy4CbgLvo3fV07+NLwLs9Zst+3JakzmIfzUy5AL8DzHcHwLO6KpLkZcBvAj+W5MaBTSfQu41xVdRosQ4NnQPAe4EPAX8I7Bho/3ZVHfHfO94HLR0zWLrjtlR1FsW7XBYpyUPpfYpubD/IpajRYp2l0trzWQoes6XRdKCvhNuItLw8BxbPY7Z6tfSm6DDLfhuRlp3nwOJ5zFap5gJ9Cd9F1wrlObB4HrM2NDflMuzlYpIbq2ps34mulcVzYPE8Zm1o5i6XJXwXXSuU58Diecza0swVuu+iy3Ng8TxmbWkm0CXp/q65N0Ul6f7KQJekRhjoktQIA12SGmGgS1Ij/g+0gsdT3kOjtwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosted Model Feature Importance\n",
    "# Extract feature importances from the fitted gradient boosting model\n",
    "feature_importances = gbr.feature_importances_\n",
    "\n",
    "# Get the indices of the largest to smallest feature importances\n",
    "sorted_index = np.argsort(feature_importances)[::-1]\n",
    "x5 = range(X5.shape[1])\n",
    "\n",
    "# Create tick labels \n",
    "feature_names = ['t-12', 't-11', 't-10', 't-9', 't-8', 't-7', 't-6', 't-5', 't-4', 't-3',\n",
    "       't-2', 't-1']\n",
    "labels = np.array(feature_names)[sorted_index]\n",
    "\n",
    "plot.bar(x5, feature_importances[sorted_index], tick_label=labels)\n",
    "\n",
    "# Set the tick lables to be the feature names, according to the sorted feature_idx\n",
    "plot.xticks(rotation=90)\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we looked at a Gradient Boosted model on a dataset that consisted of 12 lagged variables.  The dataset was split into features and target. It was further split according to a training and testing datasets.  In some ways, the feature importances of the Gradient Boosted model are similar to those of the feature importances of the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
